--数据库安装
1、是否有oralce support账号(永久的)
2、跳过软件更新
3、仅安装软件
4、单实例数据库安装
5、简体中文安装
6、企业版安装

-----------------------------------------------------------------------
生产
32G以上 内存分配50%以上(20G),64G给40G
若只有8G无须给50%
一般都不会超过70%
show parameters target;
-----------------------------------------------------------------------

-----------------------------------------------------------------------
连接数默认150
一般为8000，给一万即可
数据库进程的连接数
select count(*) from v$process;
数据库当前会话的连接数
select count(*) from v$session;
数据库最大连接数和最大session数量
show parameter processes;
select value from v$parameter where name ='processes'; 
修改连接数
alter system set processes = 3000 scope = spfile;
需重启实例
shutdown immediate;
startup
-----------------------------------------------------------------------

-----------------------------------------------------------------------
字符集(最好不可修改，安装后修改会有乱码)
询问开发商
国内一般是ZHS16GBK - GBK 16-bit Simplified Chinese 
字符集查看
服务器端字符集查看
SELECT Userenv('language') FROM dual;
-----------------------------------------------------------------------

-----------------------------------------------------------------------
磁盘的问题
数据库有问题绝对是磁盘跟不上
减少数据库对磁盘的i/o次数
-----------------------------------------------------------------------

-----------------------------------------------------------------------
阵列，存储
硬盘个数很多，硬盘转数15000，硬盘300G/600G
IOPS
硬盘个数*150
raid5 raid10 
查看系统raid级别
cat /proc/scsi/scsi
cat /proc/mdstat 
-----------------------------------------------------------------------

-----------------------------------------------------------------------
播放器
实例-数据库open后才存在：动态
内存+后台进程
database电影文件
静态，文件
select status from v$instance;
-----------------------------------------------------------------------

-----------------------------------------------------------------------
诊断数据库问题一般查看等待事件
数据库读写等操作都是在内存中执行
-----------------------------------------------------------------------

-----------------------------------------------------------------------
实例内存的分配
实例20G、数据库高速缓冲区为10G
查看实例内存分配
show parameters target;
-----------------------------------------------------------------------

-----------------------------------------------------------------------
hash算法
test表找数据(几十字节)
在某个数据文件的某个数据块上
表的对象号(每个表都有个对象号(表的唯一编号))
数据文件的唯一编号
数据块号
通过hash函数算出一个值

表的对象号
select t.OBJECT_NAME,t.OBJECT_ID from sys.dba_objects t where t.OBJECT_NAME='TT1';
数据文件编号、数据块号
select file_id,block_id,blocks from dba_extents where segment_name='TT1';
-----------------------------------------------------------------------

-----------------------------------------------------------------------
select * from test where name '张三';
TEST表的编号：2780
数据文件的编号：USE.DBF:7
块编号：235
2780+7+235 hash x
内存里有hash table
hash表的大小计算，桶数*8字节，比所有的内存块还多
bucket 桶
b1
b2-bh-bh-bh-bh(buffer head：记录数据文件、数据块信息)
b3    |
b4	  buffer(8k)(数据文件上拷贝过来的)
.
.
.

数据库的块大小是8k
桶都是连续的
b1：20000 b2:20008
hash值x除于桶数得出余，余*8定位到bx
-----------------------------------------------------------------------

-----------------------------------------------------------------------
多少个桶，buffer cache
400M 51200块，400*1024/8
大概有130000个桶(桶数量是块数量的一半以上)
有一半以上的桶分不到一个块，一个桶有可能分配到多个块
-----------------------------------------------------------------------

-----------------------------------------------------------------------
脏块：磁盘数据与内存数据不一致，断电会数据丢失
修改前生成redio记录保存至重做日志缓冲区-日志文件
-----------------------------------------------------------------------

-----------------------------------------------------------------------
高速缓冲区-达到一定条件后写入数据文件
日志缓冲区-达到一定条件后(3秒、达到3分之1、超过1M、commit) 写入日志文件
日志文件顺序写数据，数据文件分区写数据 
-----------------------------------------------------------------------

-----------------------------------------------------------------------
select id from test where name '张三';
是否存在test表，id字段，放入
语法检查
语义检查 								数据字典缓冲区
解析(很耗cpu)，生成执行计划				库高速缓冲区，缓存执行计划的
执行
返回结果

数据字典
select * from all_tables t where t.TABLE_NAME='TT1';
select * from all_tab_columns t where t.Table_Name='TT1';
-----------------------------------------------------------------------

-----------------------------------------------------------------------
数据文件：8k数据块
日志文件：顺序写，redio记录
控制文件：日志文件、数据文件信息
-----------------------------------------------------------------------

-----------------------------------------------------------------------
后台进程
DBWn		高速缓冲区-数据文件
CKPT		检查点进程
LGWR		重做日志缓冲区-日志文件-commit可触发
SMON		系统监控进程
PMON		程序监控进程：每个用户进程一一对应服务进程，连接断掉会清理掉服务进程
ARCn		归档进程
RECC		恢复进程
Others		其他进程
-----------------------------------------------------------------------

-----------------------------------------------------------------------
# CBC LATCH
SGA:SYSTEM GLOGLE AREA
BUFFER CACHE
LOG BUFFER CACHE
SHARED BOOL
凡是共享的东西，有一个机制保护
-----------------------------------------------------------------------

-----------------------------------------------------------------------
select * from test where name '张三';
TEST表的编号：2780
数据文件的编号：USE.DBF:7
块编号：235
2780+7+235 hash x
内存里有hash table
hash表的大小计算，桶数*8字节，比所有的内存块还多
bucket 桶
b1
b2-bh-bh-bh-bh(buffer head：记录数据文件、数据块信息)
b3    |
b4	  buffer(8k)(数据文件上拷贝过来的)
.
.
.
甲访问b2前获取CBC latch，未搜索完bh前不会释放CBC latch，乙访问不了b2
一个闩(CBC latch)保护连续的32个桶
热链竞争：同一个闩(减少CBC latch保护桶的数量)
热块竞争：同一个块(并发、sql语句问题)
-----------------------------------------------------------------------

-----------------------------------------------------------------------
ASMM动态调配内存(比人工配置效率高)
10g		SGA内存自动管理
11g		SGA与PGA内存自动管理
MEMORY_MAX_TARGET(20G)					最大值
MEMORY_TARGET(10G)						实际值，可修改，最多只能20G
show parameters target

判断数据库有没配置内存自动管理(ASMM)
11gMEMORY_TARGET有没有值
10gSGA_TARGET有没有值

show parameters buffer
设置的最小值
db_block_buffers		     integer	 0
log_buffer			     integer	 7069696(字节)
buffer_pool_keep		     string
buffer_pool_recycle		     string

生产系统ASMM
小系统：ASMM反而效率很高
大系统：ASMM，每一个区域，buffer cache 10G(设置最小值)
-----------------------------------------------------------------------

-----------------------------------------------------------------------
LGWR写入日志文件的条件
在DWBR进程将脏缓冲区写入数据文件之前
在重做日志记录达到缓冲区的三分之一
日志缓冲区记录的日志多于1M
每隔3秒
提交事务(执行Commit)

commit不会触发DBWR写入数据文件
-----------------------------------------------------------------------

-----------------------------------------------------------------------
oracle启动过程
1、找参数文件($ORACLE_HOME/dbs)
根据参数文件里面的参数启动实例，实例启动(SGA+后台进程)
二进制参数文件-spfileora11g.ora
文本参数文件-initora11g.ora
nomount状态

2、根据第一步实例启动之后，参数文件中定义的控制文件路径打开控制文件(cd $ORACLE_BASE;cd oradata/ora11g)
控制文件-control01.ctl  control02.ctl...
mount状态

3、控制文件记录了数据文件和日志文件相应的信息，去打开日志文件和数据文件(cd $ORACLE_BASE;cd oradata/ora11g)
数据文件-example01.dbf  sysaux01.dbf  system01.dbf  temp01.dbf  undotbs01.dbf  users01.dbf
日志文件-example01.dbf  sysaux01.dbf  system01.dbf  temp01.dbf  undotbs01.dbf  users01.dbf
open状态

二进制参数文件的命名：spfileora11g.ora
sid：ora11g
spfile*.ora
--环境变量定义的sid
export ORACLE_UNQNAME=ora11g

文本参数文件：init.ora
先二进制参数文件后文本文件
二进制文件-互相创建-文本文件(关闭数据库)
通过二进制文件创建文本文件
shutdown immediate;
create pfile from spfile;
startup

静态参数(修改不生效，重启之后才生效)：spfile
动态参数(立即生效)：both/memory
查看数据库所有参数
show parameters;
修改数据库参数
alter system set sga_target=699M scope=both/spfile/memory(都修改且生效/修改到参数文件内，当前不生效/内存修改)

表空间：容器，包含数据文件，逻辑存在
一个数据文件最大32G
create table test1(id,name) in db01.dbf;
create table test1(id,name) in tts;  

表空间tts：4个数据文件：1,2,3,4.dbf 每个大小2G
insert into 100w(100M),怎么分布到数据文件中
1.dbf 64k(区的大小)
2.dbf 64k(区的大小)
.
.
.
轮着写，写的性能IO
select extent_id,file_id,block_id,blocks from dba_extents where segment_name='TT4';

创建表，表空间就会给这个对象创建一个段：表段(表空间来给表分配空间)，段由区组成，区有数据块(8k)组成
段最开始申请一个区，区最开始的时候是由8个数据块
段要向表空间申请空间，再扩展一个区，8个块
8个块，64个块(表的大小达到64M以后)，128个块，最后128M
select extent_id,file_id,block_id,blocks from dba_extents where segment_name='TT4';
-----------------------------------------------------------------------

-----------------------------------------------------------------------
cbc latch
hash表
找数据的过程
1、根据数据文件号，块号生成hash值
2、在hash table里面找到bucket地址
3、获取cbc latch，一个lacth保护32个bucket
4、bucket，有一个指针指向bh(buffer head)
5、搜索bucket的bh链表
6、匹配bh里面的内容，跟要找的是否一样 
7、匹配到了一个bh
8、给bh，加锁：buffer pin(s或x)
9、释放CBC latch,cbc latch做两件事：保护链接，保护加buffer pin
10,进程根据bh里面ba(数据块)地址找内存块
11、找完了，将释放buffer pin锁
12、获得CBC latch，在cbc latch保护下，释放buffer pin锁
# 只有一部分读数据是以上的过程

# oracle对一部分内存读数据做了优化，对唯一索引的扫描(根、分支、叶子)，及回表数据，普通索引的根、分支，通过rowid直接扫描，CBC lacth是共享的方式
1、根据数据文件号，块号生成hash值
2、在hash table里面找到bucket地址
3、获取cbc latch(共享)，一个lacth保护32个bucket
4、bucket，有一个指针指向bh(buffer head)
5、搜索bucket的bh链表(共享)
6、匹配bh里面的内容，跟要找的是否一样 
7、匹配到了一个bh
8、进程根据bh里面ba(数据块)地址找内存块
9、根据bh地址去读buffer
10、释放CBC latch
-----------------------------------------------------------------------

-----------------------------------------------------------------------
索引：根块，分支块
		根块
	分支 分支 分支
叶子 叶子 叶子 叶子 叶子
-----------------------------------------------------------------------

-----------------------------------------------------------------------
buffer pin
等待：buffer busy wait--绝对是dml操作导致的
s：共享
x：独占
A，获得了buffer pin锁(A不做修改，只读),status:xucr
B，发现了有一个buffer pin锁：buffer clone(写)
buffer clone过程
1、bh已经有一个buffer pin:s，buffer pin:s
2、获取CBC latch，bh复制一个，链接到原来bh的后面
3、clone buffer，克隆bh和buffer
A占的bh：status:cr(状态修改为只读，buffer pin：s)
B占的bh：status:xucr(状态修改为写)，BA:x00sfas(更新buffer地址)，buffer pin：x(独占)，可修改buffer
	修改之前先生成redo记录，把redo放到log buffer，修改之后再修改buffer里面的内容
	把这个块链接ckpt
	再释放buffer pin
	结论：检查点队列脏块的顺序跟redo记录顺序是一致的

C,读A占有的buffer，这时就产生buffer busy wait，等待B修改完数据块后释放buffer pin
-----------------------------------------------------------------------

-----------------------------------------------------------------------
检查点队列-当数据由不脏变成脏块时，就会将块列到检查点队列来(按时间排序)
ckpt q												
1 2 3 4 5 6 7											redo(file 1,block 1，(后映像王五)--LRBA
														redo(file 2,block 5，后映像麻六)
														redo(file 1,block 1，后映像张七)--HRBA
(张三改成王五)buffer  (李四改成麻六)buffer
(又把王五改成张七)--此时不会再放入检查点队列，已经为脏块了，但会生成redo记录

此时若数据库宕机了，将检查点队列的脏块恢复
ckpt每3秒醒来，将redo记录的日志文件地址写到控制文件中
-----------------------------------------------------------------------

-----------------------------------------------------------------------
LRU链表：
工作组：主lru链表，辅lru链表，主lruw链表，辅lruw链表
一个数据库里面有多少个工作组，cpu_count
buffer cache所有的buffer(8k)全部都会链接到lru链表
刚开机的时候：所有的buffer都会在辅lru链表

主lru占总buffer75%
辅lru占总buffer25%

找可以覆盖的块
1、tch值小于2
2、不是脏块
3、块没有被buffer pin住
前台进程，a发生重物读

找覆盖的块
buffer cache lru chain latch
1、首先找辅lru链表(脏块肯定是tch值为1，不是脏块)
(smon进程3秒醒来一次，检查主lru长度，把主lru中，tch值为1，
不是脏块，没有被pin住块从主lru移到辅lru链表)
2、如果找到辅lru，把块链接到主的lru冷端的位置
3、如果辅lru找到可覆盖的块之前，那么就要到主lru冷端头找覆盖的块，在没有找到可覆盖的块之前，它发现有tch为1脏块，把脏块链到主lruw链表上面，它发现有tch值大于2的块，移到主lru链表热端，tch值清0，
持有时间：没有找到可覆盖的块之前，都不会释放latch，找到了之后可以释放，这个进程可以读到buffer

物理读太多
dbwr进程3s醒来，检查主lurw链表，有脏块，把这些脏块移动辅lruw链表
lruw链表，dbwr这个辅lruw链表脏块写入磁盘
1个脏块，触发写
dbwr(ckpt+主lruw(一部分脏块，也在检查点队列中))相辅相成完成的

10g如果是全表扫描一个大表
buffer cache有限的，假如20w个buffer cache
我有一个表，10w个块，表全表扫描，10w读到内存里面来

11g大表扫描直接磁盘读到pga，不进sga

free buffer wait等待事件，物理读(找不到可覆盖的buffer)
辅lru列表上没有
主lru扫描了40%的块都没有找到可覆盖的块，就会产生等待事件(休眠)，触发DBWR写辅lruw(主lruw列表移动过来的)的脏块

触发DBWR写
1、3s醒来检查ckpt长度，检查lruw有没有脏块
2、free buffer waits，40%(主lru)，触发dbwr把lruw脏块写磁盘
3、alter system checkpoint(手动执行检查点)，触发dbwr
4、日志(redo日志)切换；触发dbrw写
5、关机，dbwr写
6、表空间offline/online，触发dbwr写
7、对象做truncate触发dbwr写
8、进程搜索可覆盖的块的过程中，会看一下主lruw的长度，脏块数达到buffer数得25%也会触发写

PGA，一个是私有的，
排序和分组，hash join(内存里面排序，若内存空间不够，则放入临时表空间)

OLTP：联机交易，并发量大，每个事务处理的数据很小
OLAP：决策分析，并发量小，每个事务处理的数据大，16k性能好一些
数据块默认8k，4、8、16、32k
-----------------------------------------------------------------------

-----------------------------------------------------------------------
容灾
底层的存储复制
数据库复制

IO负载，将数据分散到各个盘上面
-----------------------------------------------------------------------

-----------------------------------------------------------------------
如何估算PGA，SGA的大小，配置数据库服务器的内存
ORACLE给的建议是：一个数据库服务器，分80%的内存给数据库，20%的内存给操作系统(64G)
OLTP系统PGA=(Total Memory)*80%*20%。余下SGA
DSS系统(OLAP)PGA=(Total Memory)*80%*70%。余下SGA
混合系统PGA=(Total Memory)*80%*20%。余下SGA

memory_target与/dev/shm的关系
ORACLE从11g版本开始，必须要确保共享内存(/dev/shm)大于ORACLE中初始化参数MEMORY_MAX_TARGET和MEMORY_MEMORY_TARGET,如果是小于，则ORACLE数据库启动时，就会触发ORA-00845:MEMORY_TARGET not supported on this system错误。
解决办法就是增大/dev/shm或是减小MEMORY_TARGET，下面是通过增加/dev/shm来解决
修改/dev/shm大小：
vim /etc/fstab
shm /dev/shm tmpfs size=18g 0 0
重新挂载
mount -o remount /dev/shm

##初始分配与最小值
memory_target:1000M
sga_target:0		初始分配的大小M_T*60% 600m  select * from v$sgastat;
pga_target:0		初始分配的大小M_T*40% 400m  select * from v$pgastat;
问题：pga_target:200m，400m             --200m设置的是最小值
	  sga_target:0     600m
若：
pga_target:500m        500m
sga_target:0		   500m
--sga_target用了300m，则pga_target可用空闲的200m

memory_target是动态参数，但最大不会大于memory_max_target(静态参数-重启数据库)的大小，
11g可以做到sga和pga自动管理，只需要给一个momory_target就行。如果sga_target或pga_aggregate_target有一个值，且是最小值(即保证值)
但仍可以为各种高速缓存设置下限值。因此，如果子缓冲区是用户设置的，则这些参数值将是Oracel DB服务器自动优化该组件时的下限值。但仅限于sga中的部分参数
DB buffer cache(default pool)
shared pool
large pool
streams pool
java pool
但以下参数仍需要手动指定：
log buffer
keep、recycle以及非标准块缓冲区
固定SGA以及其他内部分配

而对于pga中的内存区域如果指定了自动管理，则忽略所有*_area_size的设置。如sort_area_size,hash_area_size等。即如下的pga内存区域的值将不起作用。不像sga部分内存参数那样是一个最小值
bitmap_merge_area_size
create_bitmap_area_size
hash_area_size
sort_area_retained_size
sort_area_size

关于10g与自动内存管理，10g没有memory_target参数，所以只能做到sga，pga各自自动内存管理
以下是10g设置的方法，该方法也适合11g
说明：10g可以做到sga自动内存管理
1）SGA_TARGET默认值为0时，即ASMM被禁用。需要手动设置SGA各中各组件的大小。
2）当SGA_TARGET为非0时，则启用ASMM，自动调整以下各组件大小
DB buffer cache(default pool)
shared pool
large pool
streams pool
java pool
但以下参数仍需要手动指定：
log buffer
keep、recycle以及非标准块缓冲区
固定SGA以及其他内部分配

启用ASMM需要将STATISTICS_LEVEL设置成TYPICAL或ALL
启用ASMM，自动调整SGA内部组件大小后。若手动指定某一组件值，则该值为该组件的最小值。如手动设置SGA_TARGET=8G
SHARE_POOL_SIZE=1G，则ASMM在自动调整SGA内部组件大小时，保证share pool不会低于1G

select component,current_size/1024/1024 size_mb from v$sga_dynamic_components;
SGA_MAX_SIZE
SGA_MAX_SIZE指定内存中可以分配给SGA的最大值
SGA_TARGET是一个动态参数，其最大值为SGA_MAX_SIZE指定的值。但是要修改SGA_MAX_SIZE这个参数要重启系统

10g pga也可以做到自动内存管理
设置PGA_AGGREGATE_TARGET为非0，workarea_size_policy为auto时，则启用PGA自动管理，并忽略所有*_area_size的设置。如sort_area_size,hash_area_size等
测试以上结论经过测试正确。下面的测试过程
alter system set hash_area_size=1048576000 scope=spfile;
shutdown immediate;
startup
show parameters area;
hash_area_size integer 1048576000
可以看到hash_area_size为1G，而整个memory_target才700m，如果生效，不可能这个内存会超过memory_target;
则启用PGA自动管理，pga里面各个子区域的值就不是最小值，而是忽略所有*_area_size的设置

默认为启用PGA的自动管理，Oracle根据SGA的20%来动态调整PGA中专用与Work Area部分的内存大小，最小为10MB
1）设置PGA_AGGREGATE_TARGET大小的步骤
a.设置PGA_AGGEGATE_TARGET为SGA的20%，对于DSS系统，此值可能过低
b.运行典型的负载，通过oracle收集的pga统计信息来调整PGA_AGGREGATE_TARGET的值。
c.根据oracle的pga建议调整PGA_AGGREGATE_TARGET大小
2）禁用自动pga管理
为向后兼容，设置PGA_AGGREGATE_TARGET为0，即禁用pga的自动管理。可使用关联的*_area_size参数调整对应工作区的最大大小
bitmap_merge_area_size
create_bitmap_area_size
hash_area_size
sort_area_size
注意：关于排序sort_area_size和hash_area_size,如果遇到大的排序和hash join，可以会话级别加大这两个参数，因为对一个会话来讲，默认参数最多可以获得的排序和hash的内存大小不超过1G，但是在会话级别可以增加到2G(不能超过2G)，如下设置，加大这个参数可以加快大排序和大hash join操作的执行效率。
alter session set hash_area_size = 2000000000;
#####################################################################################################
一个server process能够分配最大的pga是多大的算法？
select sum(pga_used_mem)/1024/1024 from v$process;      -----当前process一共消耗的PGA	
28.8192501068115

如何设置PGA呢？
我们可以在压力测试阶段，模拟一下系统的运行，然后运行
select (select sum(pga_used_mem)/1024/1024 from v$process) /(select count(*) from v$process) from dual;
得到一个process大约占用了多少的内存，然后估算系统一共会有多少连接，比如一共有500个连接，如果processes=450，那么sessions=1.1*process+5=500,再乘以一个process需要消耗的内存，就能大约估算出PGA需要设置多大。
最好将PGA设置的值比计算出的值大一点，PGA值设定好后，就可以根据系统的性质，如果系统为OLTP，那么总的内存可以设置为PGA/0.16，最后也能估算SGA的大小
关于一个process能够分配的最大内存(串行操作)的规则：
10gR1之前，对于串行操作(非并行)一个process能够分配的最大的内存为min(5%pga_aggregate_target,100m)
10gR2之后，对于串行操作(非并行)一个process能够分配的最大内存有如下规则：
如果pga_aggregate_target<=500m，那么最大的内存为20%*pga_aggregate_target.
如果500m<pga_aggregare_target<=1000m，那么最大内存为100m
如果1000m<pga_aggregate_target<=2.5G，那么最大内存为10%*pga_aggregate_target.
如果pga_aggregare_target>2.5G，那么最大内存为2.5G
就是在非并行方式下，"期望尺寸"为min(5%pga_aggregate_target,50%*_pga_max_size,_smm_max_size)
select ksppinm,ksppstvl,ksppdesc from x$ksppi x,x$ksppcv y where x.indx = y.indx and ksppinm in ('_pga_max_size','_smm_max_size');
此处一个process能够分配的最大内存为20M，因为我的PGA=100M，符合上面的规则。
隐含参数_smm_max_size表示一个Process能够分配最大的memory

##########################################################################

下面我们通过以下的几个命令来让大家清楚memory_target的设置与PGA和SGA的关系
可以参考以下附件的结论
memory_target没有设置或等于0(11g中默认为0)
11g中默认为0则初始状态下取消了memory_target的作用，完全和10g在内存管理上一致，完全向下兼容
-----------------------------------------------------------------------

-----------------------------------------------------------------------
一般一个数据库对象对应一个数据段
任何种类的数据库对象，本质都是一种数据段。数据表、索引、回滚、聚焦这些都是数据段的一种表现形式
一个对象创建出来之后，在段层次上是分配一个分区和八个数据块

表空间是存储结构中的最高层结构

数据文件：保留128个块-位图块：记录其他块有没被占用(占用1，未占用0)--11G，10G只保留8个块
位图记录的数据：111011101001，位图负责找出没有被占用的块提供给区，找数据时直接定位到上一次寻找的块(变量)

表空间有没有碎片：什么情况下会产生
如果开启了闪回，drop了表，那么，区并不会释放，因此标记为不会下降。因为drop只是改名，而并不会真正删除表

找出表数据要插入哪个数据块里面--ASSM(段的自动管理)，记录数据块是否已写满，位图数组的不同部分可以被同时使用
如何扩展新的块--本地位图管理

创建了表对象8个块，段会保留4个块，控制端的信息L3(段头)-L2-L1-block(写数据)


创建表空间--指定数据文件，大小，是否自动扩展
create tablespace TTS datafile '/oracle/app/oracle/oradata/ora11g/tts01.dbf' size 32760M autoextend off;
增加数据文件--到85%后自动扩展
alter tablespace tts add datafile '/oracle/app/oracle/oradata/ora11g/tts02.dbf' size 100M autoextend on;
实际生产环境中：
不会数据文件自动扩展。而是一次性分16G，32G
区的大小会变化(ASSM)
段会向表空间中的所有数据文件轮流分配区

在一个区所有的块都是连续的
11G：创建新表时默认一个区都不会分配。只有向表中插入一行数据时，才会默认分配第一个区，延迟段创建。注意：在导入导出时，没有分配一个区的表是不会被导出的

统一区大小表空间，就是创建表空间时，设定区大小为一个统一值，关键字uniform size

ASSM系统管理区的大小
当表的大小小于1M时，0-15个区大小都是8个块
当表的大小大于1M时，区大小都是128个块
当表的大小大于64M时，区大小为8MB

关于区大小的讨论：
从空间利用率来讲，小区节省空间，大区会浪费空间
从性能上来讲，随记访问，大区，小区没有影响。但连续访问，大区又是更合适的。因为连续空间更多，可以减少磁头在区间的定位。
很多系统用固定的1M为1区大小，因为一次IO最多只能读1M，即使你的区是8M，也只能分8次IO
从IO角度上来讲8M区跟1M区并不能减少IO，但是8M区数据是在一起的，如果是顺序读连续IO的性能要比随记IO高很多。
因为，如果设固定区大小，基于全表扫描这种连续读方式8M区大小更好。

关于系统管理区方式位图管理的变化。
系统管理区的大小是变化的，区的大小不同，如何用二进制位来反映的使用情况？
以8个块64K为准，每个二进制位对应64k
如果分配1M的区，就需要16个位来标记

关于表空间级碎片的讨论
在统一区的大小表空间中，因为区的大小一致，不会出现碎片问题。
在系统管理区中，由于区的大小不一致，仍会存在碎片。比如说，有很多个64k的区，互相不连续，分布在数据文件的各个角落，当需要1MB的区时，这些不连续的64k区就无法重用，碎片产生了。但是这种情况很少出现，因为区不会被频繁的分配。释放。

段的概念：段只代表存储空间，在dba_objects这个视图中，object_id字段是指表的id，data_object_id字段指段的id
SQL> select object_id,data_object_id from dba_objects where object_name='TT4';

 OBJECT_ID DATA_OBJECT_ID
---------- --------------
     88708	    88708
起始情况下表ID和段ID是一样的，但对象id是不会变得，而段id在truncate时会变化

truncate这个操作就是将原来的段删除，再为表新建一个段。也就是将表原来的空间释放，再重新分配新的区。
-----------------------------------------------------------------------

-----------------------------------------------------------------------
块的结构：分为管理信息和用户数据，其中管理信息包括块头的SCN，ITL槽等。
如果删除了一行，再回滚，行的位置会变吗？测试如下附件
删除的回滚，不会改变行原来的位置，删除某行，其实只是在行上加个删除标志，声明此行所占的空间可以被覆盖。在没有提交时，事务加在行的锁并没有释放，空间仍不会被其他行覆盖。而删除行的回滚，其实就是将被删除的行重新插入一次，不需要进行寻找空间的操作，原来在哪儿就还插入到那里
如果删除后提交再插入，行的位置肯定就会发生变化了

插入行时oracle是如何在数据块内找空间的？
块中用户数据所占空间时从下往上分配的，假设，在8192字节处插入5行，每行100字节，也就是说空间已经使用到了7692字节处，那么标记位值为7692，如果删除了其中一行，并提交，标记位的值不会变，再重新插入被删除行，或插入新行，将会从7692处向上查找可用空间，删除行释放出的空间不会被使用。当标记位的值越来越小，向到达管理性信息的边界时，标记位会再变为8192
8192-300(管理空间)-10%(预留-update改变字节的大小)
-----------------------------------------------------------------------

-----------------------------------------------------------------------
ASSM的目的是大并发插入，ASSM整体结构是3层位图块+数据块
## 多个会话插入表数据，不同数据块插入
create table test表段段头是在n数据文件n块
buffer cache file_id +block_id
insert into test values(1,'a');
找数据字典，段头
在seg$ shared_pool directory cache
第一个L3块一般是段头，一个段一般只有一个L3块，L3块存放了L2块的信息，L2块存放L1块的信息，L1块指向数据块。
oracle是如何使用这个树形结构来确定向哪个块中插入数据的呢？
第一步，查找数据字典，确定段头位置
第二步，在段头中找到第一个L2块位置信息
第三步，到L2块中根据执行插入操作进程的PID号，做hash运算，得到一个随机数N，在L2中，找到第N个L1块的位置信息
第四步，在第三步中确定的L1块中，再根据执行插入操作进程的PID号，做hash运算，得到一个随机数M，在L1中找到第M好数据块
第五步，向第M号数据块中插入


L3块中虽然可以有多个L2块，但插入操作不会选择多个L2块，每次只会选择同一个L2块，直到这个L2块下面的所有数据块都被插满了，才会选择下一个L2块。
在L2中选择某个L1的时候，就是随机的了，不同session，只要有可能就会分配到不同的L1中，在L1中找数据块进也是一样，假设一个L2中有10个L1，每个L1有32个块，可以oracle真够随机，320个进程一起执行插入操作，oracle会将它们分配到320个块中去。
关于assm提高并发插入与高水位线之间的关系：
有时候有人总是经常说，怎么我的表中没有几条数据，但是还是这么慢呢，这个时候其实奥秘就是这里的高水位线了，高水位线虚高
-----------------------------------------------------------------------

-----------------------------------------------------------------------
## ORACLE用HWM(高水位)来界定一个段中使用的块和未使用的块
当我们创建一个表test时，ORACLE就会为这个对象分配一个段，在这个段中，即使我们未插入任何记录，也至少有一个区被分配(11gr2除外)，第一个区的第一个块就称为段头，段头中就储存了段的一些基本信息，其中HWM的信息就存储在此，在Oracle数据的存储中，可以把存储空间想象为一个水库，数据想象为水库中的水。水库中的水的位置有一条线叫做水位线，在Oracle中，这条线被称为高水位线。在数据库表刚建立的时候，由于没有任何数据，所以HWM为最低值。当插入了数据以后，高水位线就会上涨，但是这里也有一个特性，就是如果你采用delete语句删除数据的话，数据虽然被删除了，但是高水位线却没有降低，还是你刚才删除数据以前那么高的水位。也就是说。这条高水位线在日常的增删操作中只会上涨，不会下跌

HWM在插入数据时，当现有空间不足而进行空间的扩展时会向上移，但delete删除数据时不会往下移
ORACLE不会释放空间以供其他对象使用，空间是为新插入的行保留的，并且要适应现有行的增长。被占用的最高空间称为最高使用标记(HWM)

ORACLE的全表扫描是读取高水位标记(HWM)以下的所有块
所以问题就产生了，当用户发出一个全表扫描时，ORACLE始终必须从段头一直扫描到HWM，即使它什么也没有发现。这也就回答了第1部分提出的问题

普通插入操作，oracle一定会在高水位线下找空闲空间插入

当用直接路径插入行时(用APPEND提示插入)或通过SQL*LOADER数据块直接置于HWM之上。它下面的空间就浪费掉了

降低ORACLE表的高水位线
下面的方法都可以降低高水位线标记
1、执行表重建指令alter table table_name move;收缩表(整理碎片)，降低高水位，消除行移植和行链接，释放申请的空间
2、执行alter table table_name shrink space;注意，此命令为Oracle 10g新增功能，再执行该指令之前必须允许行移动alter table table_name enable row movement;
alter table trans shrink space --收缩表(整理碎片)，降低高水位，消除行移植和行链接，不释放申请的空间
alter table trans shrink space compact --收缩表及其索引(整理碎片)，不降低高水位，消除行移植和行链接，不释放申请的空间
alter table trans shrink space cascade --收缩表及其索引(整理碎片)，降低高水位，释放申请的空间
	shrink space限制
	IOT索引组织表
	用rowid创建的物化视图的基表
	带有函数索引的表
	securefile大对象
	压缩表
	system表空间的对象
3、复制要保留的数据到临时表t，drop原表，然后rename临时表t为原表
4、emp/imp
5、alter table table_name deallocate unused
deallocate unused为释放HWM上面的未使用空间，但是并不会释放HWM下面的自由空间，也不会移动HWM的位置
-----------------------------------------------------------------------

-----------------------------------------------------------------------
行链接
在第一次插入数据的时候如果一个block不能存放一行记录的情况下，Oracle将使用链接一个或者多个在这个段中保留的block存储这一行记录，行链接比较容易发生在比较大的行上，(例如行上有LONG、LONG RAW、LOB)等数据类型的字段，这种时候行链接是不可避免的会产生的。)

行迁移
当一行记录初始插入的时候是可以存储在一个block中的，由于更新操作导致行长增加了，而block的自由空间已经完全满了，这个时候就产生了行迁移。在这种情况下，Oracle将会迁移整行数据到一个新的block中(假设一个block中可以存储下整行数据)，Oracle会保留被迁移到一个新的block中(假设一个block中可以存储下整行数据)，Oracle会保留被迁移行的原始指针指向新的存放行数据的block，这就意味着被迁移行的ROW ID是不会改变的

段头与extent map
oracle搜索数据是从内存开始的，根据要找的数据的file_id,和block_id生成hash值去和backet匹配
但是oracle是怎么知道这个file_id和block_id的呢？
extent map就是解决这个问题的，在L3块(段头)中记录着extent map
extent map记录着一个段中所有区都在哪儿的图。全表扫描操作，就是按图读取所有区
-----------------------------------------------------------------------

-----------------------------------------------------------------------
记录登录信息
表里面插入数据
早上8:40左右登入很慢
分区表来的，800多万条记录。分区表，每天一个新的表，且固定区大小1M，128个块，由于表的高水位导致只有64个块可写

1412 1471
64块

1472 1536
64块
高水位线在1471这个位置
高水位下写完了，高水位网上非一个一个区移，以L1块包含的数据块移


中午不慢，就很正常

数据库向区中插入数据：
大量的buffer busy wait;
等待在哪个对象。
新建的分区表，早上的时候L1中只有64块，高水位线低，从而导致了buffer busy wait;
解决方案：
向新建的表中插入脏数据，提高高水位线，再删除脏数据，脚本每日执行
-----------------------------------------------------------------------

-----------------------------------------------------------------------
数据库插入脚本
#!/bin/bash
sqlplus / as sysdba <<EOF
insert into x4 values($1,'AXXX');
commit;
exec dbms_lock.sleep(10000);
EOF
10000s暂停操作是为了让会话不退出，否则一退出再进去就是同一个PID了。
chmod 755 assm.sh
./assm.sh 4&
./assm.sh 5&
./assm.sh 6&
./assm.sh 7&
./assm.sh 8&
./assm.sh 9&
./assm.sh 10&
./assm.sh 11&
./assm.sh 12&
./assm.sh 13&
./assm.sh 14&
./assm.sh 15&
./assm.sh 16&
./assm.sh 17&
./assm.sh 18&
./assm.sh 19&
./assm.sh 20&
重复执行以上语句，会发现所有的数据都会插入至132至191号块，而这个区后面的192至255(共64个块)不会写入数据。原因是oracle只使用了第一个L1块中的数据块，而没有使用第二个L1块中64个数据块。
也就是说从L2中选择L1是随机的，现在L2有两个L1，为什么只选择第一个L1呢？
在普通插入模式下，每次都是从高水位点以下寻找空间插入。而ORACLE高水点每次向后移动时，是以L1块中的数据块数量为单位的，如果这个时候有100个并发插入，那么将有36个进程不得不和另一个进程同时向一个块中插入
两个进程同时修改一个块，buffer busy waits等待。
一般一个区的第一个块通常是一个块，那么一个L1中有64个数据块，是固定的嘛？
测试结论如下：
在1M区大小的情况下，当段大小到90MB时，一个L1中的数据块从64变成256个
在8M区大小的情况下，当段大小到64MB时，一个L1中的数据块包含256个

如果高水位推到第二个L1所包含的数据块，那么高水位线下的所有数据块都可以做插入对象
-----------------------------------------------------------------------

-----------------------------------------------------------------------
system表空间
system表空间是oracle数据库最重要的一个表空间，存放了一些DDL语言产生的信息以及PL/SQL包、视图、函数、过程等，称之为数据字典，因此该表空间也具有其特殊性。建议不存放用户数据
SYSTEM用户数据
SYSTEM表空间特性
	不能脱机offine
	不能置为只读read only
	不能重命名
	不能删除
system01.dbf自动扩展

sysaux表空间
SYSAUX表空间在Oracle Database 10g中引入，作为SYSTEM表空间的辅助表空间，以前一些使用独立表空间或系统表空间的数据库组件现在在SYSAUX表空间中创建。通过分离这些组件和功能，SYSTEM表空间的负荷得以减轻，反复创建一些相关对象及组件引起SYSTEM表空间的碎片问题得以避免。如果SYSAUX表空间不可用，数据库核心功能将保持有效；使用SYSAUX表空间的特点
	不能删除
	不能重命名
	不能置为read only
	进一步独立SYSTEM表空间，保证其存储及性能。我们在做数据库规划时大可借鉴Oracle这个改进，分离重要数据及次要数据，分离稳定结构及频繁变化结构，尽量减少对重要数据及结构的影响。
	
临时表空间
Oracle临时表空间主要用来做查询和存放一些缓冲区数据。临时表空间消耗的主要原因是需要对查询的中间结构进行排序。排序和hash join
临时表空间的主要作用：
索引create或rebuild；
Order by或group by;
Distinct操作
Union或intersect或minus;
Sort-merge joins;
analyze.
在Oracle数据库中进行排序、分组汇总、索引等到作时，会产生很多的临时数据。对于这些临时数据，Oracle数据库是如何处理的呢？
通常情况下，Oracle数据库会先将这些临时数据存放到内存的PGA(程序全局区)内。在这个程序全局区中有一个叫做排序区的地方，专门用来存放这些因为排序操作而产生的临时数据。但是这个的容量是有限的。当这个排序区的大小不足以容纳排序后所产生的临时数据。但是这个的容量是有限的。当这个排序区的大小不足以容纳排序后所产生的记录时，数据库系统就会将临时数据存放到临时表空间中。这就是临时表空间的来历。在用户进行数据库操作时，排序、分组汇总、索引这些作业是少不了，其会产生大量的临时数据。为此基本上每个数据都需要用到临时表空间。而如果这个临时表空间设置不当的话，则会给数据库性能带来很大的负面影响。为此管理员在维护这个临时表空间的时候，不能够掉以轻心。要避免因为临时表空间设置不当影响数据库的性能

每个用户一个临时表空间
创建临时表空间组，所有用户共用一个临时表空间组
创建临时表空间，数据文件：16G，13M

OLTP:
memory_target:32G
正常业务的情况下：sga:10g pga:8g
刚开始设的参数不是最优值：怎么设才是最优值
select * from v$sga_target_advice;
select * from v$pga_target_advice;

表空间本地位图管理：用户数据块(位图块)，数据文件的头部128块
1个位8个块的分配情况。表空间产生碎片的问题

ASSM段的自动空间管理：
段头：L3,L2,L1不能写数据的，保留的
第一个区：8个块
1L3 1L2 2L1
当128块一个区时，几乎第一个块都是L1块

L3记录L2地址，只有第一个L2下L1下的数据块写满了才会写第二个L2块

数据字典
seg$
select * from test; 在内存读这个表的所有块。首先要知道test这个表所占的所有数据块的分布
test表 数据字段记录表的段头位置，读段头L3：extent map(区的数据块分布是连续的)
		0232321 0233321 EXTETN1				第一个区的第一个块到最后一个块地址	
		0332321 0333321 EXTETN2				第二个区的第一个块到最后一个块地址	
-----------------------------------------------------------------------

-----------------------------------------------------------------------
回滚
undo 表空间，存放数据修改前的前映像
读一致性：10:31:00 发出一条语句select * from test;  假如100w，1分钟，1分钟内表还是原来的数据，即使30s后有人删除了后50万数据，还是读100w

回滚段表空间
undo机制的提出，源自于Oracle提出的"多版本一致读"特性。在Oracle中，select操作不会阻塞任何操作，也不会被任何操作所阻塞。这就意味着，当我们对一个数据表进行DML操作，比如插入、修改和删除数据的时候，其他会话连接的select操作是可以随意进行的，而且访问的数据都是DML操作之前提交的数据。
Oracle数据是保存在"表空间、段对象、分区和数据块"的组织结构体系中。对数据的修改就是在数据块中直接的修改。如果需要同时支持对之前数据的访问，比如在系统中有一个地方需要保存数据的"前镜像pre-image"，同时一旦DML进行回滚rollback动作，恢复数据也需要这部分前镜像内容，这就衍生出了rollback segement和之后的undo表空间

数据回滚(rollback)：最基本的功能，回滚不需要的操作
数据库恢复(data recovery): 在数据库意外宕机之后需要使用UNDO数据进行回滚操作。--实例恢复
一致性读(read consistency): 提供数据库的一致性读功能，这是一个非常重要的特性。
闪回功能(Flashback): 除Flashback Database之外其它的闪回都是通过UNDO实现的，包括Flashback Query,Flashback Drop等等

先前滚，打开数据库，后回滚

回滚段的四种状态及分配方法
undo是由事务产生的，一个事务仅分一个undo段，undo段上默认只有一个事务，当有多个事务时，会优先选择空闲的undo段，只有在没有了空闲undo段时，oracle才会选择在一个undo段上建立多个事务(用it1区分)。每隔12小时会收缩一次，删除那些idl状态的extent；DML操作发生undo空间不够，则会唤醒smon进行一次收缩将undo segment里面暂时没有使用过的extend拿过来使用。
ACTIVE:
	在自动UNDO管理的模式下，当开启一个事务修改数据时，Oracle会给这个开启的事务分配回滚段用于存储被修改数据的前映像，在事务回滚或者是提交之前，这些分配的回滚区的状态称为活动状态(ACTIVE)，处于活动状态的回滚段是不能够被覆盖或者是离线(offline)的。
INACTIVE:
	当这个事务提交或者是回滚之后，所对应的回滚区则标记为非活动(Inactive)状态，处于非活动状态的回滚区不再为数据回滚或是数据库恢复等功能所用，但是UNDO的其他诸如一致性读和闪回等功能却还是有可能用到这些回滚段。因此处于Inactive的回滚区也并不意味着就可以马上丢弃，这个需要取决于UNDO的RETENTION的设置
EXPIRED:
	同样上面说到回滚或者是提交之后的回滚区将是非活动状态，然而这个非活动状态还是可以继续细分的。那些还处于UNDO RETENTION之内的回滚区的状态为未过期滚区不会轻易的被覆盖；而已过期的回滚区则随时有可能为新的事务所重复利用。
FREE:
	未使用的空间
回滚段的使用原则：

--事务：第一条DML语句到commit/rollback，查询不算事务
undo 表空间：段 undo段：区组成：数据块组成
一个事务开始，修改操作；申请一个回滚段，拿一个区(1个块)放前映象
active:写前映象的块，提交之后：inactive；再过undo_retention(默认900秒)时间，就变成了expried，空闲后为free
-----------------------------------------------------------------------














